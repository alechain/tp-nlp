{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Embeddings Entrenables (1st lab NLP) .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "h-RLYV5QPBEX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w8DRjGAHzyG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "8137cf3a-998f-433e-a6cb-27642b9d2ae8"
      },
      "source": [
        "# Usar keras 2.2.5\n",
        "#!conda install -c conda-forge keras=2.2.5\n",
        "!pip install keras --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Collecting keras\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed keras-2.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.2.5 \n"
      ],
      "metadata": {
        "id": "W7UTov-Wj_sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnLq6p7aHzyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e2a974c-e74c-4e5c-e90b-747a73975517"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6qXmkzsHzyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f589249-4166-4b7e-afbd-eceb8dff9eab"
      },
      "source": [
        "import numpy as np\n",
        "1.16.5\n",
        "np.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.21.5'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KnibsN1xUk3"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb as dataset\n",
        "#from keras.datasets import reuters as dataset\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvpowIEOHzyT"
      },
      "source": [
        "# Cargamos y analizamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ra2gF4HzyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb478b9-d9bd-4765-ce82-b09300339600"
      },
      "source": [
        "# Primer hyperparámetro\n",
        "num_words=30000\n",
        "\n",
        "(training_data, training_targets), (testing_data, testing_targets) = dataset.load_data(num_words=num_words+2)\n",
        "data = np.concatenate((training_data, testing_data), axis=0)\n",
        "targets = np.concatenate((training_targets, testing_targets), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hc30uqO5pf2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.get_word_index()"
      ],
      "metadata": {
        "id": "mh-j2O7GkJkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYWTLfB1xUlI",
        "outputId": "6717da19-05ed-4f0e-b588-de35f3da2994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Tengo dos categorías: Sentimiento positivo (1) o sentimiento negativo (0)\n",
        "num_categories = len(np.unique(targets))\n",
        "print(\"Categories:\", np.unique(targets))\n",
        "# Tengo num_words palabras únicas en el vocabulario\n",
        "print(\"Number of unique words:\", len(np.unique(np.hstack(data))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories: [0 1]\n",
            "Number of unique words: 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWw-HzNgrMgK",
        "outputId": "9cd18d28-2dbb-481a-d1c3-a590b8239212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lZ-DUxtxUlT",
        "outputId": "ff2cf1ec-33f0-47a8-ae71-27d21556025b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Longitudes promedio de los comentarios de las películas\n",
        "length = [len(i) for i in data]\n",
        "print(\"Average Review length:\", np.mean(length))\n",
        "print(\"Standard Deviation:\", round(np.std(length)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Review length: 234.75892\n",
            "Standard Deviation: 173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGeDrxcRHzya"
      },
      "source": [
        "# Impresión de comentario preprocesado con su etiqueta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnT33-acxUlZ",
        "outputId": "85df7194-7980-46ae-8846-404fbc08a57c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Imprimo cometario i'esimo con su clasificación de sentimiento\n",
        "i = 0\n",
        "print(\"Label:\", targets[i])\n",
        "# Las comentarios ya están preprocesados\n",
        "print(data[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n",
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSVq9thIxUlh",
        "outputId": "9441f705-a561-4b8e-f3db-c4dcbb54ad00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Bajamos diccionario de palabras a indices\n",
        "index = dataset.get_word_index()\n",
        "print([f'{k}:{v}' for k,v in index.items()][:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fawn:34701', 'tsukino:52006', 'nunnery:52007', 'sonja:16816', 'vani:63951', 'woods:1408', 'spiders:16115', 'hanging:2345', 'woody:2289', 'trawling:52008', \"hold's:52009\", 'comically:11307', 'localized:40830', 'disobeying:30568', \"'royale:52010\", \"harpo's:40831\", 'canet:52011', 'aileen:19313', 'acurately:52012', \"diplomat's:52013\", 'rickman:25242', 'arranged:6746', 'rumbustious:52014', 'familiarness:52015', \"spider':52016\", 'hahahah:68804', \"wood':52017\", 'transvestism:40833', \"hangin':34702\", 'bringing:2338', 'seamier:40834', 'wooded:34703', 'bravora:52018', 'grueling:16817', 'wooden:1636', 'wednesday:16818', \"'prix:52019\", 'altagracia:34704', 'circuitry:52020', 'crotch:11585', 'busybody:57766', \"tart'n'tangy:52021\", 'burgade:14129', 'thrace:52023', \"tom's:11038\", 'snuggles:52025', 'francesco:29114', 'complainers:52027', 'templarios:52125', '272:40835', '273:52028', 'zaniacs:52130', '275:34706', 'consenting:27631', 'snuggled:40836', 'inanimate:15492', 'uality:52030', 'bronte:11926', 'errors:4010', 'dialogs:3230', \"yomada's:52031\", \"madman's:34707\", 'dialoge:30585', 'usenet:52033', 'videodrome:40837', \"kid':26338\", 'pawed:52034', \"'girlfriend':30569\", \"'pleasure:52035\", \"'reloaded':52036\", \"kazakos':40839\", 'rocque:52037', 'mailings:52038', 'brainwashed:11927', 'mcanally:16819', \"tom'':52039\", 'kurupt:25243', 'affiliated:21905', 'babaganoosh:52040', \"noe's:40840\", 'quart:40841', 'kids:359', 'uplifting:5034', 'controversy:7093', 'kida:21906', 'kidd:23379', \"error':52041\", 'neurologist:52042', 'spotty:18510', 'cobblers:30570', 'projection:9878', 'fastforwarding:40842', 'sters:52043', \"eggar's:52044\", 'etherything:52045', 'gateshead:40843', 'airball:34708', 'unsinkable:25244', 'stern:7180', \"cervi's:52046\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrmkTbXyHzyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755fdd8c-4348-41d3-b9eb-edb5ab1e247d"
      },
      "source": [
        "# Armo diccionario reverso: de indices a palabras\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
        "print([f'{k}:{v}' for k,v in reverse_index.items()][:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['34701:fawn', '52006:tsukino', '52007:nunnery', '16816:sonja', '63951:vani', '1408:woods', '16115:spiders', '2345:hanging', '2289:woody', '52008:trawling', \"52009:hold's\", '11307:comically', '40830:localized', '30568:disobeying', \"52010:'royale\", \"40831:harpo's\", '52011:canet', '19313:aileen', '52012:acurately', \"52013:diplomat's\", '25242:rickman', '6746:arranged', '52014:rumbustious', '52015:familiarness', \"52016:spider'\", '68804:hahahah', \"52017:wood'\", '40833:transvestism', \"34702:hangin'\", '2338:bringing', '40834:seamier', '34703:wooded', '52018:bravora', '16817:grueling', '1636:wooden', '16818:wednesday', \"52019:'prix\", '34704:altagracia', '52020:circuitry', '11585:crotch', '57766:busybody', \"52021:tart'n'tangy\", '14129:burgade', '52023:thrace', \"11038:tom's\", '52025:snuggles', '29114:francesco', '52027:complainers', '52125:templarios', '40835:272', '52028:273', '52130:zaniacs', '34706:275', '27631:consenting', '40836:snuggled', '15492:inanimate', '52030:uality', '11926:bronte', '4010:errors', '3230:dialogs', \"52031:yomada's\", \"34707:madman's\", '30585:dialoge', '52033:usenet', '40837:videodrome', \"26338:kid'\", '52034:pawed', \"30569:'girlfriend'\", \"52035:'pleasure\", \"52036:'reloaded'\", \"40839:kazakos'\", '52037:rocque', '52038:mailings', '11927:brainwashed', '16819:mcanally', \"52039:tom''\", '25243:kurupt', '21905:affiliated', '52040:babaganoosh', \"40840:noe's\", '40841:quart', '359:kids', '5034:uplifting', '7093:controversy', '21906:kida', '23379:kidd', \"52041:error'\", '52042:neurologist', '18510:spotty', '30570:cobblers', '9878:projection', '40842:fastforwarding', '52043:sters', \"52044:eggar's\", '52045:etherything', '40843:gateshead', '34708:airball', '25244:unsinkable', '7180:stern', \"52046:cervi's\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPXo_QZ8sKes",
        "outputId": "0f14a11d-39e9-4b7f-fead-969485b00bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     1,   778,   128,    74,    12,   630,\n",
              "         163,    15,     4,  1766,  7982,  1051,     2,    32,    85,\n",
              "         156,    45,    40,   148,   139,   121,   664,   665,    10,\n",
              "          10,  1361,   173,     4,   749,     2,    16,  3804,     8,\n",
              "           4,   226,    65,    12,    43,   127,    24, 15344,    10,\n",
              "          10], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_index.get(778)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B2g47RFGs68g",
        "outputId": "3e6cab2b-0bf9-4cfb-ca46-5d250d3309ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'effort'"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhq6d5MWHzyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1357fab1-1362-4e8c-b6ec-31782bed5877"
      },
      "source": [
        "decoded = \" \".join( [reverse_index.get(i , \"#\") for i in data[5]] )\n",
        "print(data[5])\n",
        "print()\n",
        "print(decoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 15344, 10, 10]\n",
            "\n",
            "the effort still been that usually makes for of finished sucking ended and an because before if just though something know novel female i i slowly lot of above and with connect in of script their that out end his deceptively i i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBL_1v2eHzym"
      },
      "source": [
        "# Padding y formateo de data para entrenar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HifepVsJxUlo"
      },
      "source": [
        "# Hyperparametro - Longitud máxima de comentario\n",
        "maxlen=1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb8Mf33exUlu"
      },
      "source": [
        "data = pad_sequences(data,maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq-c12e5xUl8",
        "outputId": "e5dde8ec-95fa-4e90-cb1d-9cbba1454944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Verificamos que todos tengan longitud 1000\n",
        "print(len(data[0]))\n",
        "print(np.array([len(d) for d in data]).var())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXBIUZaNxUmD"
      },
      "source": [
        "data=np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gwma-IqxUmK",
        "outputId": "f3b9604f-d4b9-4f32-c717-548b3b2249df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bplIZHWNUXo"
      },
      "source": [
        "# Armar una MLP con one-hot encoding para resolver el problema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ51AMr2Nbok"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV5eg2fDNdtk"
      },
      "source": [
        "# usar maxlen y num_words para calcular la entrada\n",
        "#la entrada va a tener que ser igual a 1000*30000=30.000.000 de input shape\n",
        "# Utilizar una sola capa\n",
        "model = Sequential()\n",
        "salida_densa = 1\n",
        "input_shape = 30_000_000\n",
        "model.add(Input(shape=(30_000_000,)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXqCIIv6OWe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4ab2ee-5ed1-4bb5-da0b-94a544609b4f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 30000001  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,000,001\n",
            "Trainable params: 30,000,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZgSx1HH1w1o",
        "outputId": "773efe1e-4a38-4cf0-96f4-bcd696019119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11700000"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-RLYV5QPBEX"
      },
      "source": [
        "## ¿Por que no es viable esta red?\n",
        "Esta red no es viable porque tenemos 30.000.001 de parámetros y solamente tenemos para entrenar 50.000 Reviews de peliculas con un promedio de 234 tokens de entrada, es decir, 11.700.000 \"features reales\" (en promedio) sin contar los 0 del padding a causa del \"maxlen\", lo que indica que tenemos una mayor cantidad de parámetros  que de features para realizar el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnvzV5wiPKjs"
      },
      "source": [
        "# Armar una MLP usando Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecjdmUczPIVf"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Flatten, Dropout\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPTlDXslPO0o"
      },
      "source": [
        "# Cantidad de palabras totales contando las reservadas\n",
        "nb_words=num_words+3\n",
        "# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n",
        "embed_dim=32\n",
        "salida_capa_densa = 1\n",
        "dropout=0.5 # Hiperparámetro\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=nb_words, output_dim=embed_dim, input_length=maxlen, trainable=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(salida_capa_densa, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTs8XKCLPVqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d0d8f88-b386-47a6-a93d-f8c4498f2147"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1000, 32)          960096    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32000)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32000)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 32001     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 992,097\n",
            "Trainable params: 992,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6bygoYSP1PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3554194d-1960-4c6d-a527-c38ce1844fb6"
      },
      "source": [
        "# MODIFIQUE HYPERPARAMS A GUSTO\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4tv5kkjPuaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ff9914-b36f-418c-cc44-6ec3f6bd851b"
      },
      "source": [
        "model.fit(data,targets,batch_size=32,epochs=5,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 16s 10ms/step - loss: 0.4004 - accuracy: 0.8108 - val_loss: 0.2497 - val_accuracy: 0.8978\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1903 - accuracy: 0.9282 - val_loss: 0.2382 - val_accuracy: 0.9033\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1173 - accuracy: 0.9609 - val_loss: 0.2507 - val_accuracy: 0.8979\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 13s 10ms/step - loss: 0.0722 - accuracy: 0.9792 - val_loss: 0.2682 - val_accuracy: 0.8959\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 12s 10ms/step - loss: 0.0451 - accuracy: 0.9887 - val_loss: 0.2946 - val_accuracy: 0.8961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f481ee7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNPXfSxWQRI3"
      },
      "source": [
        "# Armar una CNN\n",
        "Abajo hay un ejemplo de arquitectur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Yi3_A4V5AS"
      },
      "source": [
        "# _________________________________________________________________\n",
        "# Layer (type)                 Output Shape              Param #   \n",
        "# =================================================================\n",
        "# embedding_12 (Embedding)     (None, 1000, 32)          960096    \n",
        "# _________________________________________________________________\n",
        "# conv1d_7 (Conv1D)            (None, 1000, 64)          14400     \n",
        "# _________________________________________________________________\n",
        "# max_pooling1d_4 (MaxPooling1 (None, 500, 64)           0         \n",
        "# _________________________________________________________________\n",
        "# conv1d_8 (Conv1D)            (None, 500, 128)          57472     \n",
        "# _________________________________________________________________\n",
        "# global_max_pooling1d_4 (Glob (None, 128)               0         \n",
        "# _________________________________________________________________\n",
        "# dropout_4 (Dropout)          (None, 128)               0         \n",
        "# _________________________________________________________________\n",
        "# dense_19 (Dense)             (None, 46)                5934      \n",
        "# ================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n"
      ],
      "metadata": {
        "id": "cqjo6oAh21Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de palabras totales contando las reservadas\n",
        "nb_words=num_words+3\n",
        "# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n",
        "embed_dim=32\n",
        "salida_capa_densa = 1\n",
        "dropout=0.5 # Hiperparámetro\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=nb_words, output_dim=embed_dim, input_length=maxlen, trainable=True))\n",
        "model.add(Conv1D(kernel_size=1,filters=64))\n",
        "model.add(MaxPool1D())\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv1D(kernel_size=1,filters=128))\n",
        "model.add(MaxPool1D())\n",
        "\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv1D(kernel_size=1,filters=256))\n",
        "model.add(MaxPool1D())\n",
        "\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv1D(kernel_size=1,filters=512))\n",
        "model.add(MaxPool1D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(salida_capa_densa, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "ypx7C5Tk2uBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuM6m3Uz4dHv",
        "outputId": "0d5db930-a220-45cf-8538-fa04a6d61508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 1000, 32)          960096    \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 1000, 64)          2112      \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 500, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 500, 64)           0         \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 500, 128)          8320      \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 250, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 250, 128)          0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 250, 256)          33024     \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 125, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 125, 256)          0         \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 125, 512)          131584    \n",
            "                                                                 \n",
            " max_pooling1d_10 (MaxPoolin  (None, 62, 512)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 31744)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 31745     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,166,881\n",
            "Trainable params: 1,166,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssxu2rPVV_d_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344e18eb-dd07-40d3-ef0e-32141c2aa730"
      },
      "source": [
        "# MODIFIQUE HYPERPARAMS A GUSTO\n",
        "adam = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzXyAjAvxUmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7edf0b6-667b-4304-cc96-6084ab9851ba"
      },
      "source": [
        "model.fit(data,targets,batch_size=32,epochs=10,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 18s 13ms/step - loss: 3.8771 - accuracy: 0.8160 - val_loss: 7.7975 - val_accuracy: 0.7821\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 7.7787 - accuracy: 0.8394 - val_loss: 5.1452 - val_accuracy: 0.8648\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 18s 14ms/step - loss: 8.1313 - accuracy: 0.8644 - val_loss: 7.4290 - val_accuracy: 0.8655\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 8.2807 - accuracy: 0.8781 - val_loss: 11.8437 - val_accuracy: 0.8576\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 10.3469 - accuracy: 0.8862 - val_loss: 20.2102 - val_accuracy: 0.8425\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 12.3518 - accuracy: 0.8923 - val_loss: 15.4726 - val_accuracy: 0.8601\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 11.3028 - accuracy: 0.9054 - val_loss: 19.1476 - val_accuracy: 0.8589\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 13.4463 - accuracy: 0.9086 - val_loss: 24.6275 - val_accuracy: 0.8805\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 13.3956 - accuracy: 0.9191 - val_loss: 29.9991 - val_accuracy: 0.8627\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 14.6972 - accuracy: 0.9217 - val_loss: 35.2004 - val_accuracy: 0.8636\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f4457fb90>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBZtuDJsM3mK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}